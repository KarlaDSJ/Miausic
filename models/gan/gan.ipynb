{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord, stream\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense, Reshape, Dropout, LSTM, Bidirectional\n",
    "from tensorflow.keras.layers import BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.legacy import Adam #Para MAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargamos los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes(files):\n",
    "    \"\"\"Obtenemos todas las notas y acordes de cada archivo midi\"\"\"\n",
    "    notes = []\n",
    "    duration = []\n",
    "\n",
    "    for file in files:\n",
    "        midi = converter.parse(file)\n",
    "        notes_to_parse = midi.flat.notes\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "                duration.append(element.duration.quarterLength)\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append(' '.join(str(n) for n in element.pitches))\n",
    "                duration.append(element.duration.quarterLength)\n",
    "\n",
    "    return pd.DataFrame.from_dict({'pitch': notes, 'duration': duration}).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing dataset/mozart/mz_570_1.mid\n",
      "Parsing dataset/mozart/mz_570_2.mid\n",
      "Parsing dataset/mozart/mz_570_3.mid\n",
      "Parsing dataset/mozart/mz_545_1.mid\n",
      "Parsing dataset/mozart/mz_332_3.mid\n",
      "Parsing dataset/mozart/mz_330_1.mid\n",
      "Parsing dataset/mozart/mz_332_2.mid\n",
      "Parsing dataset/mozart/mz_545_2.mid\n",
      "Parsing dataset/mozart/mz_330_2.mid\n",
      "Parsing dataset/mozart/mz_330_3.mid\n",
      "Parsing dataset/mozart/mz_332_1.mid\n",
      "Parsing dataset/mozart/mz_545_3.mid\n",
      "Parsing dataset/mozart/mz_331_2.mid\n",
      "Parsing dataset/mozart/mz_333_1.mid\n",
      "Parsing dataset/mozart/mz_331_3.mid\n",
      "Parsing dataset/mozart/mz_331_1.mid\n",
      "Parsing dataset/mozart/mz_333_3.mid\n",
      "Parsing dataset/mozart/mz_333_2.mid\n",
      "Parsing dataset/mozart/mz_311_1.mid\n",
      "Parsing dataset/mozart/mz_311_2.mid\n",
      "Parsing dataset/mozart/mz_311_3.mid\n",
      "Parsing dataset/balakir/islamei.mid\n",
      "Parsing dataset/liszt/liz_rhap09.mid\n",
      "Parsing dataset/liszt/liz_et_trans8.mid\n",
      "Parsing dataset/liszt/liz_donjuan.mid\n",
      "Parsing dataset/liszt/liz_liebestraum.mid\n",
      "Parsing dataset/liszt/liz_et2.mid\n",
      "Parsing dataset/liszt/liz_et_trans5.mid\n",
      "Parsing dataset/liszt/liz_et_trans4.mid\n",
      "Parsing dataset/liszt/liz_et3.mid\n",
      "Parsing dataset/liszt/liz_rhap12.mid\n",
      "Parsing dataset/liszt/liz_rhap10.mid\n",
      "Parsing dataset/liszt/liz_et1.mid\n",
      "Parsing dataset/liszt/liz_rhap15.mid\n",
      "Parsing dataset/liszt/liz_et4.mid\n",
      "Parsing dataset/liszt/liz_et5.mid\n",
      "Parsing dataset/liszt/liz_rhap02.mid\n",
      "Parsing dataset/liszt/liz_et6.mid\n",
      "Parsing dataset/burgm/burg_sylphen.mid\n",
      "Parsing dataset/burgm/burg_quelle.mid\n",
      "Parsing dataset/burgm/burg_perlen.mid\n",
      "Parsing dataset/burgm/burg_erwachen.mid\n",
      "Parsing dataset/burgm/burg_spinnerlied.mid\n",
      "Parsing dataset/burgm/burg_geschwindigkeit.mid\n",
      "Parsing dataset/burgm/burg_gewitter.mid\n",
      "Parsing dataset/burgm/burg_agitato.mid\n",
      "Parsing dataset/burgm/burg_trennung.mid\n",
      "Parsing dataset/haydn/haydn_43_1.mid\n",
      "Parsing dataset/haydn/haydn_43_2.mid\n",
      "Parsing dataset/haydn/haydn_8_4.mid\n",
      "Parsing dataset/haydn/haydn_43_3.mid\n",
      "Parsing dataset/haydn/haydn_8_1.mid\n",
      "Parsing dataset/haydn/haydn_8_3.mid\n",
      "Parsing dataset/haydn/haydn_8_2.mid\n",
      "Parsing dataset/haydn/haydn_9_3.mid\n",
      "Parsing dataset/haydn/hay_40_1.mid\n",
      "Parsing dataset/haydn/haydn_9_2.mid\n",
      "Parsing dataset/haydn/hay_40_2.mid\n",
      "Parsing dataset/haydn/haydn_9_1.mid\n",
      "Parsing dataset/haydn/haydn_7_3.mid\n",
      "Parsing dataset/haydn/haydn_7_2.mid\n",
      "Parsing dataset/haydn/haydn_7_1.mid\n",
      "Parsing dataset/haydn/haydn_33_1.mid\n",
      "Parsing dataset/haydn/haydn_33_2.mid\n",
      "Parsing dataset/haydn/haydn_33_3.mid\n",
      "Parsing dataset/haydn/haydn_35_1.mid\n",
      "Parsing dataset/haydn/haydn_35_2.mid\n",
      "Parsing dataset/haydn/haydn_35_3.mid\n",
      "Parsing dataset/schumann/schum_abegg.mid\n",
      "Parsing dataset/schumann/scn68_10.mid\n",
      "Parsing dataset/schumann/scn15_10.mid\n",
      "Parsing dataset/schumann/scn16_8.mid\n",
      "Parsing dataset/schumann/scn15_11.mid\n",
      "Parsing dataset/schumann/scn15_13.mid\n",
      "Parsing dataset/schumann/scn15_12.mid\n",
      "Parsing dataset/schumann/scn68_12.mid\n",
      "Parsing dataset/schumann/scn15_8.mid\n",
      "Parsing dataset/schumann/scn15_9.mid\n",
      "Parsing dataset/schumann/scn15_7.mid\n",
      "Parsing dataset/schumann/scn15_6.mid\n",
      "Parsing dataset/schumann/scn15_4.mid\n",
      "Parsing dataset/schumann/scn15_5.mid\n",
      "Parsing dataset/schumann/scn15_1.mid\n",
      "Parsing dataset/schumann/scn15_2.mid\n",
      "Parsing dataset/schumann/scn15_3.mid\n",
      "Parsing dataset/schumann/scn16_6.mid\n",
      "Parsing dataset/schumann/scn16_7.mid\n",
      "Parsing dataset/schumann/scn16_5.mid\n",
      "Parsing dataset/schumann/scn16_4.mid\n",
      "Parsing dataset/schumann/scn16_1.mid\n",
      "Parsing dataset/schumann/scn16_3.mid\n",
      "Parsing dataset/schumann/scn16_2.mid\n",
      "Parsing dataset/tschai/ty_august.mid\n",
      "Parsing dataset/tschai/ty_dezember.mid\n",
      "Parsing dataset/tschai/ty_november.mid\n",
      "Parsing dataset/tschai/ty_juni.mid\n",
      "Parsing dataset/tschai/ty_april.mid\n",
      "Parsing dataset/tschai/ty_maerz.mid\n",
      "Parsing dataset/tschai/ty_februar.mid\n",
      "Parsing dataset/tschai/ty_januar.mid\n",
      "Parsing dataset/tschai/ty_juli.mid\n",
      "Parsing dataset/tschai/ty_september.mid\n",
      "Parsing dataset/tschai/ty_mai.mid\n",
      "Parsing dataset/tschai/ty_oktober.mid\n",
      "Parsing dataset/beeth/waldstein_1.mid\n",
      "Parsing dataset/beeth/beethoven_opus90_2.mid\n",
      "Parsing dataset/beeth/waldstein_2.mid\n",
      "Parsing dataset/beeth/beethoven_opus90_1.mid\n",
      "Parsing dataset/beeth/waldstein_3.mid\n",
      "Parsing dataset/beeth/beethoven_opus10_2.mid\n",
      "Parsing dataset/beeth/beethoven_opus10_3.mid\n",
      "Parsing dataset/beeth/elise.mid\n",
      "Parsing dataset/beeth/beethoven_opus10_1.mid\n",
      "Parsing dataset/beeth/appass_2.mid\n",
      "Parsing dataset/beeth/appass_3.mid\n",
      "Parsing dataset/beeth/appass_1.mid\n",
      "Parsing dataset/beeth/beethoven_les_adieux_3.mid\n",
      "Parsing dataset/beeth/pathetique_1.mid\n",
      "Parsing dataset/beeth/mond_1.mid\n",
      "Parsing dataset/beeth/beethoven_les_adieux_2.mid\n",
      "Parsing dataset/beeth/mond_3.mid\n",
      "Parsing dataset/beeth/pathetique_2.mid\n",
      "Parsing dataset/beeth/pathetique_3.mid\n",
      "Parsing dataset/beeth/mond_2.mid\n",
      "Parsing dataset/beeth/beethoven_les_adieux_1.mid\n",
      "Parsing dataset/beeth/beethoven_opus22_1.mid\n",
      "Parsing dataset/beeth/beethoven_opus22_2.mid\n",
      "Parsing dataset/beeth/beethoven_hammerklavier_4.mid\n",
      "Parsing dataset/beeth/beethoven_opus22_3.mid\n",
      "Parsing dataset/beeth/beethoven_hammerklavier_1.mid\n",
      "Parsing dataset/beeth/beethoven_opus22_4.mid\n",
      "Parsing dataset/beeth/beethoven_hammerklavier_3.mid\n",
      "Parsing dataset/beeth/beethoven_hammerklavier_2.mid\n",
      "Parsing dataset/granados/gra_esp_4.mid\n",
      "Parsing dataset/granados/gra_esp_2.mid\n",
      "Parsing dataset/granados/gra_esp_3.mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 2 - C Maj.mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 19 - A Min.mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 3 - C Min.mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 18 - A Maj.mid\n",
      "Parsing dataset/lofi/Piano MIDI (2).mid\n",
      "Parsing dataset/lofi/Rhodes MIDI (7).mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 11 - A Maj.mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 7 - E Min.mid\n",
      "Parsing dataset/lofi/Rhodes MIDI (6).mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 13 - E Min.mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 18 - G Maj.mid\n",
      "Parsing dataset/lofi/9.mid\n",
      "Parsing dataset/lofi/Piano MIDI (3).mid\n",
      "Parsing dataset/lofi/8.mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 3 - D Maj.mid\n",
      "Parsing dataset/lofi/Piano MIDI.mid\n",
      "Parsing dataset/lofi/16.mid\n",
      "Parsing dataset/lofi/Piano MIDI (4).mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 22 - B Min.mid\n",
      "Parsing dataset/lofi/Lofi Piano MIDI.mid\n",
      "Parsing dataset/lofi/Rhodes MIDI.mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 9 - D Maj.mid\n",
      "Parsing dataset/lofi/17.mid\n",
      "Parsing dataset/lofi/Piano Chords MIDI (3).mid\n",
      "Parsing dataset/lofi/15.mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 11 - E Maj.mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 17 - A Maj.mid\n",
      "Parsing dataset/lofi/Piano MIDI (8).mid\n",
      "Parsing dataset/lofi/14.mid\n",
      "Parsing dataset/lofi/Piano 2 MIDI.mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 21 - A Min.mid\n",
      "Parsing dataset/lofi/10.mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 13 - A Min.mid\n",
      "Parsing dataset/lofi/11.mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 5 - D Maj.mid\n",
      "Parsing dataset/lofi/Piano Chords MIDI (2).mid\n",
      "Parsing dataset/lofi/13.mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 1 - C Maj.mid\n",
      "Parsing dataset/lofi/Piano MIDI (5).mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 17 - G Maj.mid\n",
      "Parsing dataset/lofi/12.mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 1 - C Maj.mid\n",
      "Parsing dataset/lofi/Rhodes MIDI (3).mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 14 - F Min.mid\n",
      "Parsing dataset/lofi/Piano MIDI (6).mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 10 - F Min.mid\n",
      "Parsing dataset/lofi/E-Piano MIDI.mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 15 - F Maj.mid\n",
      "Parsing dataset/lofi/E-Piano Chords MIDI.mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 15 - A Maj.mid\n",
      "Parsing dataset/lofi/20.mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 9 - F Min.mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 19 - G Maj.mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 12 - E Min.mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 14 - A Min.mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 8 - F Maj.mid\n",
      "Parsing dataset/lofi/Piano Chords MIDI.mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 6 - D Min.mid\n",
      "Parsing dataset/lofi/19.mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 6 - D Min.mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 7 - D Maj.mid\n",
      "Parsing dataset/lofi/18.mid\n",
      "Parsing dataset/lofi/E-Piano MIDI (2).mid\n",
      "Parsing dataset/lofi/Piano MIDI (7).mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 2 - C Min.mid\n",
      "Parsing dataset/lofi/Rhodes MIDI (2).mid\n",
      "Parsing dataset/lofi/Rhodes MIDI (9).mid\n",
      "Parsing dataset/lofi/6.mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 22 - B Min.mid\n",
      "Parsing dataset/lofi/Piano MIDI 1.mid\n",
      "Parsing dataset/lofi/7.mid\n",
      "Parsing dataset/lofi/Rhodes MIDI (5).mid\n",
      "Parsing dataset/lofi/Piano 1 MIDI.mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 12 - A Min.mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 4 - D Maj.mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 5 - D Min.mid\n",
      "Parsing dataset/lofi/5.mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 20 - A Min.mid\n",
      "Parsing dataset/lofi/Piano MIDI 2.mid\n",
      "Parsing dataset/lofi/4.mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 10 - D Maj.mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 4 - D Maj.mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 21 - A Min.mid\n",
      "Parsing dataset/lofi/merge_from_ofoct.mid\n",
      "Parsing dataset/lofi/1.mid\n",
      "Parsing dataset/lofi/Cymatics - Eternity MIDI 16 - A Maj.mid\n",
      "Parsing dataset/lofi/Rhodes MIDI (4).mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 8 - D Maj.mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 16 - F Maj.mid\n",
      "Parsing dataset/lofi/3.mid\n",
      "Parsing dataset/lofi/Cymatics - Lofi MIDI 20 - G Min.mid\n",
      "Parsing dataset/lofi/2.mid\n",
      "Parsing dataset/lofi/Rhodes MIDI (8).mid\n",
      "Parsing dataset/albeniz/alb_se8.mid\n",
      "Parsing dataset/albeniz/alb_esp3.mid\n",
      "Parsing dataset/albeniz/alb_se4.mid\n",
      "Parsing dataset/albeniz/alb_se5.mid\n",
      "Parsing dataset/albeniz/alb_esp2.mid\n",
      "Parsing dataset/albeniz/alb_se7.mid\n",
      "Parsing dataset/albeniz/alb_se6.mid\n",
      "Parsing dataset/albeniz/alb_esp1.mid\n",
      "Parsing dataset/albeniz/alb_esp5.mid\n",
      "Parsing dataset/albeniz/alb_se2.mid\n",
      "Parsing dataset/albeniz/alb_se3.mid\n",
      "Parsing dataset/albeniz/alb_esp4.mid\n",
      "Parsing dataset/albeniz/alb_esp6.mid\n",
      "Parsing dataset/albeniz/alb_se1.mid\n",
      "Parsing dataset/debussy/DEB_CLAI.MID\n",
      "Parsing dataset/debussy/deb_prel.mid\n",
      "Parsing dataset/debussy/DEB_PASS.MID\n",
      "Parsing dataset/debussy/debussy_cc_6.mid\n",
      "Parsing dataset/debussy/debussy_cc_4.mid\n",
      "Parsing dataset/debussy/deb_menu.mid\n",
      "Parsing dataset/debussy/debussy_cc_1.mid\n",
      "Parsing dataset/debussy/debussy_cc_2.mid\n",
      "Parsing dataset/debussy/debussy_cc_3.mid\n",
      "Parsing dataset/bach/bach_847.mid\n",
      "Parsing dataset/bach/bach_846.mid\n",
      "Parsing dataset/bach/bach_850.mid\n",
      "Parsing dataset/muss/muss_2.mid\n",
      "Parsing dataset/muss/muss_3.mid\n",
      "Parsing dataset/muss/muss_1.mid\n",
      "Parsing dataset/muss/muss_4.mid\n",
      "Parsing dataset/muss/muss_5.mid\n",
      "Parsing dataset/muss/muss_7.mid\n",
      "Parsing dataset/muss/muss_6.mid\n"
     ]
    }
   ],
   "source": [
    "songs = glob.glob('dataset/**/*')\n",
    "notes = get_notes(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 262\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitch</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296290</th>\n",
       "      <td>C#4 F4 C#5 A4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296296</th>\n",
       "      <td>B-2</td>\n",
       "      <td>6.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296332</th>\n",
       "      <td>C6 C5</td>\n",
       "      <td>1/3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296338</th>\n",
       "      <td>B-4 B-5</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296339</th>\n",
       "      <td>B-2 B-1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20941 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                pitch duration\n",
       "0                 B-4      2.0\n",
       "1                 B-3      2.0\n",
       "2                  F4      1.0\n",
       "3                  F3      1.0\n",
       "4                  D4      2.0\n",
       "...               ...      ...\n",
       "296290  C#4 F4 C#5 A4      1.0\n",
       "296296            B-2     6.75\n",
       "296332          C6 C5      1/3\n",
       "296338        B-4 B-5      6.0\n",
       "296339        B-2 B-1      6.0\n",
       "\n",
       "[20941 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of files:', len(songs))\n",
    "notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN\n",
    "\n",
    "### Definimos la red que identificara si la muestra dada es generada por la otra red o una real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(in_shape):\n",
    "    \"\"\"Red encargada de decidir si lo generado es real o fake\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, input_shape=in_shape, return_sequences=True))\n",
    "    model.add(Bidirectional(LSTM(512)))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(100))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt = Adam(learning_rate=0.00002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definimos la red que crea pistas musicales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(seq_shape,latent_dim=100):\n",
    "    \"\"\"Red encargada de generar piezas musicales\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(np.prod(seq_shape), activation='tanh'))\n",
    "    model.add(Reshape(seq_shape))\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEfinimos la red generatica (GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model):\n",
    "    \"\"\"Red generativa (un denerador y un discriminador)\"\"\"\n",
    "    d_model.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(g_model)\n",
    "    model.add(d_model)\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generamos muestras para entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\"Creamos las secuencias para la red\"\"\"\n",
    "    sequence_length = 100\n",
    "    #Obtenemos todas las notas y las mapeamos a un número\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(set(notes)))\n",
    "    network_input = []\n",
    "    # Creamos las secuencias\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "\n",
    "    # Hacemos reshape para que sea compatible con la re LSTM y normalizamos (-1 a 1)\n",
    "    network_input = np.reshape(network_input, (len(network_input), sequence_length, 1))\n",
    "    network_input = (network_input - float(n_vocab) / 2) / (float(n_vocab) / 2)\n",
    "\n",
    "    return network_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    \"\"\"Tomamos pista reales\"\"\"\n",
    "    train_notes = np.array(dataset['pitch'])\n",
    "    n_vocab = len(train_notes)\n",
    "    X_train = prepare_sequences(train_notes, n_vocab)\n",
    "    ix = np.random.randint(0, len(X_train), n_samples)\n",
    "    X = X_train[ix]\n",
    "    y = np.ones((n_samples, 1))\n",
    "    return X, y\n",
    " \n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    \"\"\"Generamos ruido\"\"\"\n",
    "    x_input = np.random.randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "    \"\"\"Generamos una pista con el modelo generador\"\"\"\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    X = g_model.predict(x_input)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(disc_loss, gen_loss):\n",
    "    plt.plot(disc_loss, c='red')\n",
    "    plt.plot(gen_loss, c='blue')\n",
    "    plt.title(\"GAN Loss per Epoch\")\n",
    "    plt.legend(['Discriminator', 'Generator'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.savefig('GAN_Loss_per_Epoch_final.png')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(epoch, g_model, d_loss, g_loss, disc_loss, gen_loss):\n",
    "    \"\"\"\n",
    "    Nos muestra el rendimiento de la red que discrimina y la que genera\n",
    "    Guarda el modelo de generación\n",
    "    \"\"\"\n",
    "    ##Falta mostrar bien las métricas y agregar las que el profe pidio\n",
    "    print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "    disc_loss.append(d_loss[0])\n",
    "    gen_loss.append(g_loss)\n",
    "    filename = 'generator_model_%03d.h5' % (epoch + 1)\n",
    "    g_model.save(filename)\n",
    "\n",
    "def train(g_model, d_model, dataset, latent_dim=100, n_epochs=20, n_batch=128):\n",
    "    \"\"\"\n",
    "    Entrenamos la red GAN\n",
    "    g_model: es la red generadora\n",
    "    d_model: es la red discriminadora\n",
    "    dataset: conjunto de notas\n",
    "    \"\"\"\n",
    "    gan_model = define_gan(g_model, d_model)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    disc_loss = []\n",
    "    gen_loss =[]\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        #Entrenamos al discriminador\n",
    "        X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "        X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        X, y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))\n",
    "        d_loss = d_model.train_on_batch(X, y)\n",
    "        # Entrenamos el generador \n",
    "        X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "        y_gan = np.ones((n_batch, 1))\n",
    "        g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            summarize_performance(i,g_model,d_loss,g_loss,disc_loss,gen_loss)\n",
    "    \n",
    "    plot_loss(disc_loss,gen_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = define_discriminator((100,1))\n",
    "g_model = define_generator((100,1))\n",
    "train(g_model,d_model, notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_note(note_c, instr):\n",
    "    \"\"\"Regresa una nota\"\"\"\n",
    "    new_note = note.Note(note_c)\n",
    "    new_note.storedInstrument = instr\n",
    "    return new_note\n",
    "\n",
    "def get_chord(pattern, offset, instr):\n",
    "    \"\"\"REgresa un arcorde\"\"\"\n",
    "    notes_in_chord = pattern.split(' ')\n",
    "    notes = []\n",
    "    for current_note in notes_in_chord:\n",
    "        notes.append(get_note(current_note, instr))\n",
    "    new_chord = chord.Chord(notes)\n",
    "    new_chord.offset = offset\n",
    "\n",
    "def get_music(model, dataset, length=500):\n",
    "    \"\"\"Generamos una pista\"\"\"\n",
    "    latent_dim=100\n",
    "    n_vocab = len(set(dataset))\n",
    "    generator_model = load_model(model)\n",
    "    \n",
    "    #Generamos una pista empezando por una alearoria\n",
    "    predictions = generator_model.predict(np.random.normal(0, 1, (1, latent_dim)))\n",
    "    #Creamos el diccionario para saber el nombre de los acordes\n",
    "    pred_notes = [x * (n_vocab / 2) + (n_vocab / 2) for x in predictions[0]]\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(set(dataset)))\n",
    "    pred_notes_mapped = [int_to_note[int(x[0])] for x in pred_notes]\n",
    "    \n",
    "    return pred_notes_mapped[:length]  \n",
    "\n",
    "def create_midi(pred_notes_mapped, instr, filename):\n",
    "    \"\"\"Convertimos una pista a midi\"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    #Convertimos las notas y los acordes correspondientes en música\n",
    "    for item in pred_notes_mapped:\n",
    "        pattern = item[0]\n",
    "        # pattern is a chord\n",
    "        if ' ' in pattern:\n",
    "            output_notes.append(get_chord(pattern,offset,instr))\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = get_note(pattern, instr)\n",
    "            new_note.offset = offset\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        #Para que no se empalmen\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='{}.mid'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_music = get_music('generator_model_001.h5', np.array(notes['pitch']))\n",
    "midi_gan = create_midi(generated_music, instrument.Violin(), 'music_gan3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
